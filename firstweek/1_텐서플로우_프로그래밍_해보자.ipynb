{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.텐서플로우 프로그래밍 해보자.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kei01138/3minuteDeeplearning/blob/master/1_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%ED%95%B4%EB%B3%B4%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9uyph9Bb7srE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 텐서플로우 프로그래밍 해보자\n",
        "\n",
        "텐서플로우는 딥러닝 프레임워크로 유명하지만, 사실 딥러닝용으로만 사용할 수 있는 것은 아닙니다.   \n",
        "그래프 형태의 수학적 계산을 수행하는 핵심 라이브러리를 구현한 후,   \n",
        "그 위에 딥러닝을 포함한 여러 머신러닝을 쉽게 할 수 있는 다양한 라이브러리를 올린 형태입니다.  \n",
        "\n",
        "이를 위해 텐서플로우는 일반적인 프로그래밍 방식과는 약간 다른 개념들을 포함합니다.   \n",
        "이러한 텐서플로우를 사용하는 데 필요한 **텐서(Tensor)**, **플레이스홀더(Placeholder)**, **변수(Variable)**   \n",
        "그리고 **연산**의 개념과 **그래프**를 실행하는 기본적인 방법을 배워봅니다 \n",
        "\n",
        "## 텐서와 그래프 실행\n",
        "\n",
        "새로운 프로그래밍 언어나 라이브러리를 학습하는 가장 좋은 방법은 직접 코드를 입력해가며 배우는 것이 가장 쉽고 재미있는 방법입니다.\n",
        "\n",
        "하나씩 공부해봅시다\n",
        "\n",
        "먼저 텐서플로를 사용하기 위해 라이브러리를 가져옵시다\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LGDxCCfy7Z1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08_8K5ZY7g8L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음은 **tf.constant** 상수를 **hello** 변수에 저장합시다.  \n",
        "텐서플로의 상수는 일반 프로그래밍 언어에서 써온 상수와 같다고 보면 됩니다"
      ]
    },
    {
      "metadata": {
        "id": "e_CEd-85JkRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "259f998e-b514-43f9-dedd-5ab977f6981e"
      },
      "cell_type": "code",
      "source": [
        "hello = tf.constant('Hello, Tensorflow!')\n",
        "print(hello)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_12:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c8o7LA-1Jqdo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "여기까지 입력하고 소스코드를 실행하면 다음 결과를 보실 수 있습니다.\n",
        "\n",
        "\n",
        "```shell\n",
        "Tensor(\"Const:0\", shape=(), dtype=string)\n",
        "```\n",
        "\n",
        "**hello** 변수의 값을 출력한 결과로,  \n",
        "hello가 텐서플로의 **텐서(Tensor)** 라는 자료형이고,  \n",
        "상수를 담고 있음을 의미합니다.  \n",
        "\n",
        "텐서는 텐서플로에서 다양한 수학식을 계싼하기 위해 가장 기본적이고 중요한 자료형이며,  \n",
        "다음과 같이 **랭크(Rank)** 와 **셰이프(Shape)** 라는 개념을 가지고 있습니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "ouOj-xC1Jpse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba753946-195f-408a-c4b9-3337ef4c769c"
      },
      "cell_type": "code",
      "source": [
        "3 # 랭크가 0인 텐서; 셰이프는 []\n",
        "[1.,2.,3.] # 랭크가 1인 텐서; 셰이프는 [3]\n",
        "[[1.,2.,3.], [4.,5.,6.]] # 랭크가 2인 텐서; 셰이프는 [2,3]\n",
        "[[[1.,2.,3.]], [[7.,8.,9.]]] # 랭크가 3인 텐서; 셰이프는 [2,1,3]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[1.0, 2.0, 3.0]], [[7.0, 8.0, 9.0]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "9s_UN7HjK_Y8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "텐서 자료형의 형태는 배열과 비슷하다고 생각하면 됩니다.  \n",
        "보는 바와 같이 랭크는 차원의 수를 나타내는 것으로써,  \n",
        "랭크가 0이면 스칼라, 1이면 벡터, 2면 행렬, 3 이상이면 n-Tensor 또는 n차원 텐서라고 부릅니다.  \n",
        "그리고 셰이프는 각 차원의 요소 개수로, 텐서의 구조를 설명해줍니다.  \n",
        "텐서를 출력할 때 나오는 dtype은 해당 텐서에 담긴 요소들의 자료형입니다.  \n",
        "string, float, int 등이 올 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "이러한 텐서를 이용해 다양한 **연산**을 수행할 수 있으며, 덧셈은 다음처럼 간단히 할 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "DEuaDCo8LhNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28b5c3cf-3007-46f8-95de-fc86a12a5508"
      },
      "cell_type": "code",
      "source": [
        "# 그래프 생성\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(32)\n",
        "c = tf.add(a,b)\n",
        "print(c)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Add_11:0\", shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFzb8b5pLuII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "일반적인 프로그래머라면 이 코드를 실행하면 42가 나올 것으로 생각할 수 있습니다.  \n",
        "하지만 다음과 같이 텐서의 형태를 출력합니다.  \n",
        "\n",
        "\n",
        "\n",
        "```shell\n",
        "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UsNh_Aw8L7s9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "그 이유는 텐서플로 프로그램의 구조가 다음의 두가지로 분리되어 있기 때문입니다.\n",
        "\n",
        "> 1.그래프 생성  -> tf.constant 사용 했던 부분  \n",
        "> 2.그래프 실행  -> sess.run(c), 연산을 실제로 수행\n",
        "\n",
        "**그래프**는 간단하게 말해 텐서들의 연산 모음이라고 생각합니다.  \n",
        "텐서플로우는 텐서와 텐서의 연산들을 먼저 정의해 그래프를 만들고,  \n",
        "이후 필요할 때 연산을 실행하는 코드를 넣어 **원하는 시점**에 실제 연산을 수행하도록 합니다.  \n",
        "참고로 이러한 방식을 **지연 실행**이라고 하며, 함수형 프로그래밍에서 많이 사용합니다.  \n",
        "\n",
        "그래프의 실행은 Session 안에서 이뤄져야 하며,  \n",
        "다음과 같이 Session 객체와 run 메서드를 이용하면 됩니다\n"
      ]
    },
    {
      "metadata": {
        "id": "Q3QsYMJHL6to",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65062df1-626f-428b-9944-c24f4b1f28aa"
      },
      "cell_type": "code",
      "source": [
        "# 그래프 실행\n",
        "sess = tf.Session()\n",
        "\n",
        "print(sess.run(hello))\n",
        "print(sess.run([a,b,c]))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, Tensorflow!\n",
            "[10, 32, 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XB7ndbNdNeG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 코드를 실행하면 다음과 같이 기대한 계산 결과를 볼 수 있습니다.  \n",
        "\n",
        "\n",
        "```\n",
        "Hello, Tensorflow!\n",
        "[10, 32, 42]\n",
        "```\n",
        "\n",
        "아래는 전체 코드입니다\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# 텐서플로우의 기본적인 구성을 익힙니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "# tf.constant: 말 그대로 상수입니다.\n",
        "hello = tf.constant('Hello, TensorFlow!')\n",
        "print(hello)\n",
        "\n",
        "# 그래프 생성\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(32)\n",
        "c = tf.add(a, b)  # a + b 로도 쓸 수 있음\n",
        "print(c)\n",
        "\n",
        "# 위에서 변수와 수식들을 정의했지만, 실행이 정의한 시점에서 실행되는 것은 아닙니다.\n",
        "# 다음처럼 Session 객제와 run 메소드를 사용할 때 계산이 됩니다.\n",
        "# 따라서 모델을 구성하는 것과, 실행하는 것을 분리하여 프로그램을 깔끔하게 작성할 수 있습니다.\n",
        "# 그래프를 실행할 세션을 구성합니다.\n",
        "sess = tf.Session()\n",
        "# sess.run: 설정한 텐서 그래프(변수나 수식 등등)를 실행합니다.\n",
        "print(sess.run(hello))\n",
        "print(sess.run([a, b, c]))\n",
        "\n",
        "# 세션을 닫습니다.\n",
        "sess.close()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8QYhSaFwNz1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 플레이스홀더와 변수\n",
        "\n",
        "텐서플로로 프로그래밍할 때 알아야 할 가장 중요한 개념 두 개가 있다면 바로 플레이스홀더와 변수입니다.\n",
        "\n",
        "**플레이스홀더**는 그래프에 사용할 입력값을 나중에 받기 위해 사용하는 매개변수라고 생각하면 됩니다.  \n",
        "그리고 **변수**는 그래프를 최적화하는 용도로 텐서플로가 학습한 결과를 갱신하기 위해 사용하는 변수입니다.  \n",
        "이 변수의 값들이 바로 신경망의 성능을 좌우하게 됩니다.\n",
        "\n",
        "아마 잘 이해되지 않는 분도 계실 텐데, 저 역시 처음 텐서플로를 접했을 때 가장 혼란스러웠던 개념입니다.  \n",
        "알고보면 쉬운 개념이라 코드를 계속 따라가다 보면 곧 이해하실 수 있을 겁니다.\n",
        "\n",
        "먼저 플레이스 홀더는 다음과 같이 사용합니다"
      ]
    },
    {
      "metadata": {
        "id": "9jo04po00bN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70ce1630-021b-4cba-d770-b588a2b4bd23"
      },
      "cell_type": "code",
      "source": [
        "# None은 크기가 정해지지 않았음을 의미합니다\n",
        "X = tf.placeholder(tf.float32, [None, 3])\n",
        "print(X)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder_4:0\", shape=(?, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ugfhvW9X0mEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "위 코드를 실행하면 다음과 같이 Placeholder라는 (?,3) 모양의 float32 자료형을 가진 텐서가 생성된 것을 확인할 수 있습니다\n",
        "\n",
        "\n",
        "```shell\n",
        "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n",
        "```\n",
        "\n",
        "나중에 플레이스홀더 X에 넣을 자료를 다음과 같이 정의해볼 수 있습니다.  \n",
        "앞서 텐서 모양을 (?,3)으로 정의했으므로, 두 번째 차원은 요소를 3개씩 가지고 있어야 합니다\n"
      ]
    },
    {
      "metadata": {
        "id": "sr2H73Ue0lHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data = [[1,2,3],[4,5,6]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFCKvSW72CAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음은 변수들을 정의해보겠습니다"
      ]
    },
    {
      "metadata": {
        "id": "q4etCobl2Bub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random_normal([3,2]))\n",
        "b = tf.Variable(tf.random_normal([2,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r8XhOnMy2OK_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "각각 W와 b에 텐서플로의 변수를 생성하여 할당합니다.  \n",
        "W는 [3,2] 행렬 형태의 텐서, b는 [2,1] 행렬 형태의 텐서로,   \n",
        "tf.random_normal 함수를 이용해 **정규분포**의 무작위 값으로 초기화합니다.  \n",
        "물론 다른 생성 함수를 사용하거나, 다음처럼 직접 원하는 텐서의 형태의 데이터를 만들어서 넣어줄 수도 있습니다.\n",
        "\n",
        "```python\n",
        "W = tf.variable([[0.1,0.1],[0.2,0.2],[0.3,0.3]])\n",
        "```\n",
        "다음으로 입력값과 변수들을 계산할 수식을 작성해보겠습니다.  \n",
        "X와 W가 행렬이기 때문에 tf.matmul 함수를 사용하여야 합니다.  \n",
        "행렬이 아닌 경우에는 단순히 곱셈 연산자(*)나 tf.mul 함수를 사용하면 됩니다.\n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "id": "1Xdqg65H3E9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "expr = tf.matmul(X,W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctzwCDEy3JeZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "텐서플로우로 딥러닝을 하기 위해서 반드시 수학을 잘 알아야 하는 것은 아닙니다.  \n",
        "하지만 꼭 하나 알고 있어야 하는 것이 있다면 행렬인데, 특히 그중 딱 하나!  \n",
        "행렬곱 정의는 알고 있는 것이 좋습니다 \n",
        "\n",
        "[행렬곱 정의](https://ko.wikipedia.org/wiki/%ED%96%89%EB%A0%AC_%EA%B3%B1%EC%85%88)\n",
        "\n",
        "행렬곱 정의에 따라, 앞서 X에 넣을 데이터를 [2,3] 형태의 행렬로 정의하였으므로,   \n",
        "행렬곱을 하기 위해서 W의 형태를 [3,2]로 정의한 것입니다.  \n",
        "참고로 [2,3] 행렬이라며 2가 행의 개수, 3이 열의 개수입니다.\n",
        "\n",
        "이제 연산을 실행하고 결과를 출력하여, 설정한 텐서들과 계산된 그래프의 결과를 확인해보겠습니다"
      ]
    },
    {
      "metadata": {
        "id": "ZoEAd5wJ6OO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7e6051a6-2f2e-491b-95a6-c429e56c9975"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print(\"=== x_data ===\")\n",
        "print(x_data)\n",
        "print(\"=== W ===\")\n",
        "print(sess.run(W))\n",
        "print(\"=== b ===\")\n",
        "print(sess.run(b))\n",
        "print(\"=== expr ===\")\n",
        "print(sess.run(expr, feed_dict={X: x_data}))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== x_data ===\n",
            "[[1, 2, 3], [4, 5, 6]]\n",
            "=== W ===\n",
            "[[-0.8638351  -0.8311099 ]\n",
            " [ 0.6512873   0.9720324 ]\n",
            " [ 0.35349658  1.4516944 ]]\n",
            "=== b ===\n",
            "[[-1.0245268]\n",
            " [-0.1978673]]\n",
            "=== expr ===\n",
            "[[ 0.47470248  4.443511  ]\n",
            " [ 1.7242085  10.048021  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4V6EjwU37LD4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**tf.global_variables_initializer**는 앞에 정의한 변수들을 초기화하는 함수입니다.  \n",
        "기존의 학습한 값들을 가져와 사용하는 것이 아닌 처음 실행하는 것이라면,  \n",
        "연산을 실행하기 전엔 반드시 이 함수를 이용해 변수들을 초기화해야 합니다.  \n",
        "\n",
        "**feed_dict** 매개변수는 그래프를 실행할 때 사용할 입력값을 지정합니다.  \n",
        "\n",
        "**expr** 수식에는 X,W,b를 사용했는데, 이중 X가 플레이스홀더라 X에 값을 넣어주지 않으면  \n",
        "계산에 사용할 값이 없으므로 에러가 납니다.  \n",
        "따라서 미리 정의해둔 x_data를 X의 값으로 넣어주었습니다\n",
        "\n",
        "```shell\n",
        "=== x_data ===\n",
        "[[1, 2, 3], [4, 5, 6]]\n",
        "=== W ===\n",
        "[[ 1.1002327   0.43592995]\n",
        " [ 1.3414483  -0.7337341 ]\n",
        " [-0.09329127  1.0130547 ]]\n",
        "=== b ===\n",
        "[[-0.6259896]\n",
        " [ 0.9517739]]\n",
        "=== expr ===\n",
        "[[ 2.8772657  1.3816364]\n",
        " [11.500198   5.105151 ]]\n",
        "```\n",
        "실행한 결과를 보면 X(즉 x_data)는 [2,3], W는 [3,2] 형태이고,   \n",
        "결과값은 행과 열의 수가 각각 X의 행의 개수와 W의 열의 개수인 [2,2] 형태임을 확인할 수 있습니다.  \n",
        "구체적인 수치는 문서와 다를텐데, 앞서 변수 W와 b를 무작위 앖으로 초기화 했기 때문입니다.\n",
        "\n",
        "아래는 전체 코드입니다\n",
        "\n",
        "\n",
        "```python\n",
        "# 플레이스홀더와 변수의 개념을 익혀봅니다\n",
        "import tensorflow as tf\n",
        "\n",
        "# tf.placeholder: 계산을 실행할 때 입력값을 받는 변수로 사용합니다.\n",
        "# None 은 크기가 정해지지 않았음을 의미합니다.\n",
        "# 빈 통?을 만들어봅니다\n",
        "X = tf.placeholder(tf.float32, [None, 3])\n",
        "print(X)\n",
        "\n",
        "# X 플레이스홀더에 넣을 값 입니다.\n",
        "# 플레이스홀더에서 설정한 것 처럼, 두번째 차원의 요소의 갯수는 3개 입니다.\n",
        "x_data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "# tf.Variable: 그래프를 계산하면서 최적화 할 변수들입니다. 이 값이 바로 신경망을 좌우하는 값들입니다.\n",
        "# tf.random_normal: 각 변수들의 초기값을 정규분포 랜덤 값으로 초기화합니다.\n",
        "# Y = W(가중치) * X + b(편향)\n",
        "W = tf.Variable(tf.random_normal([3, 2]))\n",
        "b = tf.Variable(tf.random_normal([2, 1]))\n",
        "\n",
        "# 입력값과 변수들을 계산할 수식을 작성합니다.\n",
        "# tf.matmul 처럼 mat* 로 되어 있는 함수로 행렬 계산을 수행합니다.\n",
        "expr = tf.matmul(X, W) + b\n",
        "\n",
        "sess = tf.Session()\n",
        "# 위에서 설정한 Variable 들의 값들을 초기화 하기 위해\n",
        "# 처음에 tf.global_variables_initializer 를 한 번 실행해야 합니다.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print(\"=== x_data ===\")\n",
        "print(x_data)\n",
        "print(\"=== W ===\")\n",
        "print(sess.run(W))\n",
        "print(\"=== b ===\")\n",
        "print(sess.run(b))\n",
        "print(\"=== expr ===\")\n",
        "# expr 수식에는 X 라는 입력값이 필요합니다.\n",
        "# 따라서 expr 실행시에는 이 변수에 대한 실제 입력값을 다음처럼 넣어줘야합니다.\n",
        "print(sess.run(expr, feed_dict={X: x_data}))\n",
        "\n",
        "sess.close()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xg0pcS3G8ppF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 선형 회귀 모델 구현하기\n",
        "\n",
        "**선형 회귀**란 간단하게 말해, 주어진 x와 y값을 가지고 서로 간의 관계를 파악하는 것입니다.  \n",
        "이 관계를 알고 나면 새로운 x 값이 주어졌을 때 y 값을 쉽게 알 수 있습니다.  \n",
        "어떤 입력에 대한 출력을 예측하는 것, 이것이 바로 머신러닝의 기본입니다.\n",
        "\n",
        "이제 텐서플로의 최적화 함수를 이용해 X와 Y의 상관관계를 분석하는   \n",
        "기초적인 선형 회귀 모델을 만들고 실행해보겠습니다.  \n",
        "여기서는 다음과 같이 주어진 x_data와 y_data의 상관관계를 파악해보고자 합니다."
      ]
    },
    {
      "metadata": {
        "id": "2_bMNq9B8RBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data = [1,2,3]\n",
        "y_data = [1,2,3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VmRA4J6RHxZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "먼저 x와 y의 상관관계를 설명하기 위한 변수들인 W와 b를   \n",
        "각각 -1.0부터 1.0 사이의 **균등분포**를 가진 무작위 값으로 초기화합니다."
      ]
    },
    {
      "metadata": {
        "id": "sKEuqpXTH9Yp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
        "b = tf.Variable(tf.random_uniform([1],-1.0,1.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0tDPYGkIJYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음은 자료를 입력받을 플레이스 홀더를 설정합니다"
      ]
    },
    {
      "metadata": {
        "id": "QrZTId9FIMYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, name=\"Y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_j8CG3miIb4n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "그 다음으로 X와 Y의 상관관계(여기선 선형관계)를 분석하기 위한 수식을 작성합니다"
      ]
    },
    {
      "metadata": {
        "id": "Vtl7xrG8Ih7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hypothesis = W * X + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSgyzUT8IkNe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**이 수식은 W와의 곱과 b와의 합을 통해 X와 Y의 관계를 설명하겠다는 뜻입니다.**  \n",
        "다시 말해 X가 주어졌을 때 Y를 만들어 낼 수 있는 W와 b를 찾아내겠다는 의미이기도 합니다.  \n",
        "W는 **가중치(weight)**, b는 **편향(bias)** 이라고 하며,  \n",
        "이 수식은 선형 회귀는 물론 신경망 학습에 가장 기본이 되는 수식입니다.  \n",
        "여기서는 W와 X가 행렬이 아니므로 tf.matmul이 아니라 기본 곱셈 연산자를 사용했습니다.\n",
        "\n",
        "다음으로 손실 함수를 작성해보겠습니다.  \n",
        "**손실 함수**는 한 쌍(x,y)의 데이터에 **손실값**을 계산하는 함수입니다.  \n",
        "손실값이란 실제값과 모델로 예측한 값이 얼마나 차이가 나는가를 나타내는 값입니다.  \n",
        "즉, 손실값이 작을수록 그 모델이 X와 Y의 관계를 잘 설명하고 있다는 뜻이고,  \n",
        "주어진 X값에 대한 Y값을 정확하게 예측할 수 있다는 뜻입니다.  \n",
        "그리고 이 손실을 전체 데이터에 대해 구한 경우 이를 **비용**이라고 합니다.  \n",
        "\n",
        "#### 즉, 학습이란 변수들의 값을 다양하게 넣어 계산해보면서 \n",
        "#### 이 손실을 최소화하는 W와 b의 값을 구하는 것입니다.\n",
        "\n",
        "손실값으로는 **예측값과 실제값의 거리**를 가장 많이 사용하며, 우리도 이를 사용합니다.  \n",
        "따라서 손실값은 예측값에서 실제값을 뺀 뒤 제곱하여,  \n",
        "그리고 비용은 모든 데이터에 대한 손실값의 평균을 내어 구합니다"
      ]
    },
    {
      "metadata": {
        "id": "QXx2685wJ_le",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NqRlBkuhKJBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "텐서플로우는 이러한 수식 계산을 위한 다양한 함수를 구현해 제공합니다  \n",
        "[다양한 함수 공부하기](https://www.tensorflow.org/api_docs/)\n",
        "\n",
        "마지막으로 텐서플로우가 기본 제공하는 **경사하강법(gradient descent)** 최적화 함수를 이용해   \n",
        "손실값을 최소화하는 연산 그래프를 생성합니다.  "
      ]
    },
    {
      "metadata": {
        "id": "pODNL3phKtf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nX4I-NsTKgJH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**최적화 함수**란 가중치와 편향 값을 변경해가면서 손실값을 최소화하는  \n",
        "가장 최적화된 가중치와 편향 값을 찾아주는 함수입니다.  \n",
        "이때 값들은 무작위로 변경하면 시간이 너무 오래 걸리고 학습 시간도 에측하기 어려울 것입니다.  \n",
        "따라서 빠르게 최적화하기 위한, 즉 빠르게 학습하기 위한 다양한 방법을 사용합니다.  \n",
        "\n",
        "경사하강법은 그러한 최적화 방법 중 가장 기본적인 알고리즘으로,   \n",
        "다음 그래프와 같이 함수의 기울기를 구하고 기울기가 낮은 쪽으로 계속 이동시키면서  \n",
        "최적의 값을 찾아 나가는 방법입니다.  \n",
        "\n",
        "최적화 함수의 매개변수인 learning_rate, 즉 **학습률**은 학습을 얼마나 '급하게' 할 것인가를 설정하는 값입니다.  \n",
        "값이 너무 크면 최적의 손실값을 찾지 못하고 지나치게 되고, 값이 너무 적으면 학습 속도가 매우 느려집니다.  \n",
        "이렇게 학습을 진행하는 과정에 영향을 주는 변수를 **하이퍼파라미터**라 하며,  \n",
        "이 값에 따라 학습 속도나 신경망 성능이 크게 달라질 수 있습니다.  \n",
        "머신러닝에서는 이 하이퍼파리미터를 잘 튜닝하는 것이 큰 과제이기도 합니다.  \n",
        "\n",
        "\n",
        "이제 선형 회귀 모델을 다 만들었으니, 그래프를 실행해 학습을 시키고 결과를 확인해보겠습니다\n",
        "\n",
        "먼저 앞 절에서와 같이 세션을 생셩하고 변수들을 초기화합니다.  \n",
        "한가지, 이번에는 파이썬의 with 기능을 이용해 세션 블록을 만들고 세션 종료를 자동으로 처리하도록 만들어봤습니다\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uxKgIrUCL7fj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELQQSCilMCm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음은 최적화를 수행하는 그래프인 train_op를 실행하고,   \n",
        "실행 시마다 변화하는 손실값을 출력하는 코드입니다.  \n",
        "\n",
        "학습을 100번 수행하며, feed_dict 매개변수를 통해,  \n",
        "상관관계를 알아내고자 하는 데이터인 x_data와 y_data를 입력해줍니다."
      ]
    },
    {
      "metadata": {
        "id": "RLOXMBgUMSMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "357eb9dd-d6ec-46af-e4bb-3f3cbc33d47b"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for step in range(100):\n",
        "    _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, \n",
        "                                                        Y: y_data})\n",
        "\n",
        "    print(step, cost_val, sess.run(W), sess.run(b))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 14.477139, array([0.75695276], dtype=float32), array([0.9890936], dtype=float32))\n",
            "(1, 0.29238936, array([0.58815944], dtype=float32), array([0.8884938], dtype=float32))\n",
            "(2, 0.11727575, array([0.61714643], dtype=float32), array([0.87553126], dtype=float32))\n",
            "(3, 0.10977927, array([0.62426394], dtype=float32), array([0.8535664], dtype=float32))\n",
            "(4, 0.10454166, array([0.6335244], dtype=float32), array([0.8331475], dtype=float32))\n",
            "(5, 0.09957555, array([0.6423093], dtype=float32), array([0.81310827], dtype=float32))\n",
            "(6, 0.09484563, array([0.6509106], dtype=float32), array([0.7935629], dtype=float32))\n",
            "(7, 0.0903404, array([0.65930223], dtype=float32), array([0.77448606], dtype=float32))\n",
            "(8, 0.08604916, array([0.6674924], dtype=float32), array([0.75586796], dtype=float32))\n",
            "(9, 0.08196176, array([0.6754857], dtype=float32), array([0.7376974], dtype=float32))\n",
            "(10, 0.07806852, array([0.6832867], dtype=float32), array([0.71996367], dtype=float32))\n",
            "(11, 0.07436019, array([0.69090027], dtype=float32), array([0.7026562], dtype=float32))\n",
            "(12, 0.07082803, array([0.6983309], dtype=float32), array([0.68576485], dtype=float32))\n",
            "(13, 0.067463644, array([0.7055828], dtype=float32), array([0.6692795], dtype=float32))\n",
            "(14, 0.064259075, array([0.7126604], dtype=float32), array([0.6531905], dtype=float32))\n",
            "(15, 0.061206743, array([0.71956784], dtype=float32), array([0.63748825], dtype=float32))\n",
            "(16, 0.058299378, array([0.72630924], dtype=float32), array([0.6221635], dtype=float32))\n",
            "(17, 0.055530097, array([0.7328886], dtype=float32), array([0.60720706], dtype=float32))\n",
            "(18, 0.052892387, array([0.7393098], dtype=float32), array([0.59261024], dtype=float32))\n",
            "(19, 0.050379936, array([0.7455765], dtype=float32), array([0.57836425], dtype=float32))\n",
            "(20, 0.047986824, array([0.7516927], dtype=float32), array([0.5644608], dtype=float32))\n",
            "(21, 0.045707468, array([0.7576619], dtype=float32), array([0.5508916], dtype=float32))\n",
            "(22, 0.043536294, array([0.76348746], dtype=float32), array([0.5376485], dtype=float32))\n",
            "(23, 0.04146831, array([0.7691731], dtype=float32), array([0.5247238], dtype=float32))\n",
            "(24, 0.03949855, array([0.77472204], dtype=float32), array([0.5121098], dtype=float32))\n",
            "(25, 0.037622336, array([0.78013754], dtype=float32), array([0.49979904], dtype=float32))\n",
            "(26, 0.035835233, array([0.7854229], dtype=float32), array([0.48778424], dtype=float32))\n",
            "(27, 0.034133032, array([0.79058117], dtype=float32), array([0.47605821], dtype=float32))\n",
            "(28, 0.032511685, array([0.7956155], dtype=float32), array([0.46461412], dtype=float32))\n",
            "(29, 0.030967342, array([0.8005287], dtype=float32), array([0.4534451], dtype=float32))\n",
            "(30, 0.029496392, array([0.80532384], dtype=float32), array([0.4425446], dtype=float32))\n",
            "(31, 0.028095283, array([0.8100037], dtype=float32), array([0.43190613], dtype=float32))\n",
            "(32, 0.026760748, array([0.81457114], dtype=float32), array([0.42152342], dtype=float32))\n",
            "(33, 0.025489599, array([0.81902874], dtype=float32), array([0.41139027], dtype=float32))\n",
            "(34, 0.024278825, array([0.82337916], dtype=float32), array([0.40150073], dtype=float32))\n",
            "(35, 0.023125537, array([0.827625], dtype=float32), array([0.39184892], dtype=float32))\n",
            "(36, 0.022027055, array([0.83176875], dtype=float32), array([0.38242915], dtype=float32))\n",
            "(37, 0.020980766, array([0.8358129], dtype=float32), array([0.37323582], dtype=float32))\n",
            "(38, 0.01998419, array([0.8397599], dtype=float32), array([0.3642635], dtype=float32))\n",
            "(39, 0.01903489, array([0.8436119], dtype=float32), array([0.35550684], dtype=float32))\n",
            "(40, 0.01813073, array([0.8473714], dtype=float32), array([0.34696072], dtype=float32))\n",
            "(41, 0.0172695, array([0.8510405], dtype=float32), array([0.33862], dtype=float32))\n",
            "(42, 0.016449196, array([0.85462135], dtype=float32), array([0.3304798], dtype=float32))\n",
            "(43, 0.015667843, array([0.85811615], dtype=float32), array([0.3225353], dtype=float32))\n",
            "(44, 0.014923609, array([0.86152697], dtype=float32), array([0.31478179], dtype=float32))\n",
            "(45, 0.014214735, array([0.86485577], dtype=float32), array([0.30721465], dtype=float32))\n",
            "(46, 0.013539512, array([0.8681045], dtype=float32), array([0.2998294], dtype=float32))\n",
            "(47, 0.012896374, array([0.8712752], dtype=float32), array([0.2926217], dtype=float32))\n",
            "(48, 0.012283799, array([0.8743697], dtype=float32), array([0.2855873], dtype=float32))\n",
            "(49, 0.011700292, array([0.8773897], dtype=float32), array([0.278722], dtype=float32))\n",
            "(50, 0.0111445235, array([0.8803372], dtype=float32), array([0.27202168], dtype=float32))\n",
            "(51, 0.010615159, array([0.8832138], dtype=float32), array([0.2654825], dtype=float32))\n",
            "(52, 0.010110932, array([0.88602126], dtype=float32), array([0.25910047], dtype=float32))\n",
            "(53, 0.009630647, array([0.8887612], dtype=float32), array([0.25287187], dtype=float32))\n",
            "(54, 0.009173183, array([0.8914353], dtype=float32), array([0.246793], dtype=float32))\n",
            "(55, 0.008737455, array([0.8940452], dtype=float32), array([0.24086028], dtype=float32))\n",
            "(56, 0.008322424, array([0.8965922], dtype=float32), array([0.23507015], dtype=float32))\n",
            "(57, 0.0079270955, array([0.8990781], dtype=float32), array([0.22941923], dtype=float32))\n",
            "(58, 0.007550569, array([0.90150416], dtype=float32), array([0.22390415], dtype=float32))\n",
            "(59, 0.0071918946, array([0.90387195], dtype=float32), array([0.21852165], dtype=float32))\n",
            "(60, 0.0068502873, array([0.9061828], dtype=float32), array([0.21326855], dtype=float32))\n",
            "(61, 0.0065248893, array([0.9084381], dtype=float32), array([0.2081417], dtype=float32))\n",
            "(62, 0.0062149516, array([0.91063917], dtype=float32), array([0.20313811], dtype=float32))\n",
            "(63, 0.00591974, array([0.9127874], dtype=float32), array([0.19825482], dtype=float32))\n",
            "(64, 0.0056385486, array([0.9148839], dtype=float32), array([0.19348891], dtype=float32))\n",
            "(65, 0.005370708, array([0.91693], dtype=float32), array([0.18883756], dtype=float32))\n",
            "(66, 0.005115598, array([0.91892695], dtype=float32), array([0.18429802], dtype=float32))\n",
            "(67, 0.004872601, array([0.9208759], dtype=float32), array([0.17986764], dtype=float32))\n",
            "(68, 0.0046411497, array([0.922778], dtype=float32), array([0.17554374], dtype=float32))\n",
            "(69, 0.004420697, array([0.9246344], dtype=float32), array([0.17132379], dtype=float32))\n",
            "(70, 0.004210711, array([0.9264461], dtype=float32), array([0.16720527], dtype=float32))\n",
            "(71, 0.0040106834, array([0.92821425], dtype=float32), array([0.16318578], dtype=float32))\n",
            "(72, 0.0038201816, array([0.92994], dtype=float32), array([0.15926293], dtype=float32))\n",
            "(73, 0.00363872, array([0.9316242], dtype=float32), array([0.15543436], dtype=float32))\n",
            "(74, 0.0034658797, array([0.9332679], dtype=float32), array([0.15169781], dtype=float32))\n",
            "(75, 0.0033012424, array([0.93487203], dtype=float32), array([0.1480511], dtype=float32))\n",
            "(76, 0.0031444437, array([0.9364377], dtype=float32), array([0.14449207], dtype=float32))\n",
            "(77, 0.0029950654, array([0.93796563], dtype=float32), array([0.14101855], dtype=float32))\n",
            "(78, 0.0028528012, array([0.93945694], dtype=float32), array([0.13762859], dtype=float32))\n",
            "(79, 0.0027172936, array([0.94091237], dtype=float32), array([0.1343201], dtype=float32))\n",
            "(80, 0.002588221, array([0.9423328], dtype=float32), array([0.13109113], dtype=float32))\n",
            "(81, 0.0024652805, array([0.943719], dtype=float32), array([0.12793978], dtype=float32))\n",
            "(82, 0.0023481764, array([0.945072], dtype=float32), array([0.12486421], dtype=float32))\n",
            "(83, 0.0022366357, array([0.9463925], dtype=float32), array([0.12186257], dtype=float32))\n",
            "(84, 0.002130394, array([0.9476811], dtype=float32), array([0.11893306], dtype=float32))\n",
            "(85, 0.0020292015, array([0.9489389], dtype=float32), array([0.116074], dtype=float32))\n",
            "(86, 0.0019328072, array([0.9501663], dtype=float32), array([0.11328363], dtype=float32))\n",
            "(87, 0.0018409956, array([0.9513643], dtype=float32), array([0.1105604], dtype=float32))\n",
            "(88, 0.0017535525, array([0.9525334], dtype=float32), array([0.10790261], dtype=float32))\n",
            "(89, 0.00167026, array([0.95367455], dtype=float32), array([0.10530873], dtype=float32))\n",
            "(90, 0.0015909198, array([0.95478815], dtype=float32), array([0.10277715], dtype=float32))\n",
            "(91, 0.001515349, array([0.95587504], dtype=float32), array([0.10030646], dtype=float32))\n",
            "(92, 0.0014433669, array([0.9569357], dtype=float32), array([0.09789513], dtype=float32))\n",
            "(93, 0.0013748031, array([0.957971], dtype=float32), array([0.09554183], dtype=float32))\n",
            "(94, 0.0013095072, array([0.9589814], dtype=float32), array([0.0932451], dtype=float32))\n",
            "(95, 0.0012473058, array([0.95996743], dtype=float32), array([0.09100353], dtype=float32))\n",
            "(96, 0.001188052, array([0.96092975], dtype=float32), array([0.08881585], dtype=float32))\n",
            "(97, 0.0011316193, array([0.961869], dtype=float32), array([0.08668078], dtype=float32))\n",
            "(98, 0.0010778649, array([0.9627856], dtype=float32), array([0.08459701], dtype=float32))\n",
            "(99, 0.0010266673, array([0.9636802], dtype=float32), array([0.08256336], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-drvMpYPMpbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 학습의 진행 상황을 출력해보면 다음과 같이 손실값과 변수들의 변화를 확인할 수 있습니다.  \n",
        "다음과 같이 손실값이 점점 줄어든다면 학습이 정상적으로 이뤄지고 있는 것입니다.\n",
        "\n",
        "```shell\n",
        "(0, 18.750364, array([1.2408829], dtype=float32), array([-0.04855856], dtype=float32))\n",
        "(1, 0.22635157, array([1.0354823], dtype=float32), array([-0.13520001], dtype=float32))\n",
        "(2, 0.0049655237, array([1.0564455], dtype=float32), array([-0.12235291], dtype=float32))\n",
        "(3, 0.0022135882, array([1.0527042], dtype=float32), array([-0.12046052], dtype=float32))\n",
        "(4, 0.0020783849, array([1.0516979], dtype=float32), array([-0.1174501], dtype=float32))\n",
        "(5, 0.001979311, array([1.0504265], dtype=float32), array([-0.11463923], dtype=float32))\n",
        "(6, 0.0018852801, array([1.0492175], dtype=float32), array([-0.11188197], dtype=float32))\n",
        "(7, 0.0017957288, array([1.048034], dtype=float32), array([-0.10919257], dtype=float32))\n",
        "(8, 0.0017104292, array([1.0468793], dtype=float32), array([-0.10656763], dtype=float32))\n",
        "(9, 0.0016291835, array([1.0457523], dtype=float32), array([-0.10400582], dtype=float32))\n",
        "(10, 0.0015517954, array([1.0446525], dtype=float32), array([-0.10150557], dtype=float32))\n",
        "... (이하 생략)\n",
        "```\n",
        "이제 두근거리는 마음으로 학습에 사용되지 않았던 값인 5와 2.5를 X값으로 넣고 결과를 확인해봅니다\n"
      ]
    },
    {
      "metadata": {
        "id": "yXe_5HrcP69Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "451c5682-4675-475a-ff4b-0310f3e9fa40"
      },
      "cell_type": "code",
      "source": [
        "print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
        "print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-c5487e2599fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X: 5, Y:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X: 2.5, Y:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RQKtiZl3QJKS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "저는 결과가 다음처럼 나왔습니다.\n",
        "\n",
        "\n",
        "```shell\n",
        "'X: 5, Y:4.9358253'\n",
        "'X: 2.5, Y:2.4946632'\n",
        "```\n",
        "### 기대한 대로 X가 5일 때는 Y값으로 5 근처를, 2.5일 때는 2.5 근처를 정확히 예측해내었습니다.  \n",
        "### 텐서플로와 머신러닝의 세계로 오신 것을 환영합니다!\n",
        "\n",
        "아래는 전체 코드입니다\n",
        "\n",
        "```python\n",
        "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "# 학습 데이터\n",
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "# 가중치, 편향 초깃값 설정\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "\n",
        "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
        "X = tf.placeholder(tf.float32, name=\"X\")\n",
        "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
        "# y = W * x + b\n",
        "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
        "hypothesis = W * X + b\n",
        "\n",
        "# 손실 함수를 작성합니다.\n",
        "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "# 비용을 최소화 하는 것이 최종 목표\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "# 세션을 생성하고 초기화합니다.\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # 최적화를 100번 수행합니다.\n",
        "    for step in range(100):\n",
        "        # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
        "        # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
        "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "        print(step, cost_val, sess.run(W), sess.run(b))\n",
        "\n",
        "    # 최적화가 완료된 모델에 테스트 값을 넣고 결과가 잘 나오는지 확인해봅니다.\n",
        "    print(\"\\n=== Test ===\")\n",
        "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
        "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))\n",
        "```\n",
        "\n"
      ]
    }
  ]
}